{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\goura\\OneDrive\\Desktop\\projects\\email spam\\spam (or) ham.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                                sms\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      Class                                                sms\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5568   ham               Will Ã¼ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "5572  spam  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[5573 rows x 2 columns]>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5573, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data cleaning and preprocessng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    # Remove special characters and symbols\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lowercase(text):\n",
    "    # Convert text to lowercase\n",
    "    lowercased_text = text.lower()\n",
    "    return lowercased_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    # Tokenize the text into individual words\n",
    "    words = text.split()\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "    # Reconstruct the text without stop words\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Class                                                sms  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...   \n",
      "1   ham                      Ok lar... Joking wif u oni...   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
      "3   ham  U dun say so early hor... U c already then say...   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
      "\n",
      "                                         cleaned_sms  \n",
      "0  go jurong point crazy available bugis n great ...  \n",
      "1                            ok lar joking wif u oni  \n",
      "2  free entry wkly comp win fa cup final tkts st ...  \n",
      "3                u dun say early hor u c already say  \n",
      "4        nah dont think goes usf lives around though  \n"
     ]
    }
   ],
   "source": [
    "# Apply data cleaning to the 'sms' column\n",
    "data['cleaned_sms'] = data['sms'].apply(remove_special_characters)\n",
    "data['cleaned_sms'] = data['cleaned_sms'].apply(convert_to_lowercase)\n",
    "data['cleaned_sms'] = data['cleaned_sms'].apply(remove_stop_words)\n",
    "\n",
    "# Display the updated data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['cleaned_sms'])\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes multinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Multinomial Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_predictions = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning for SVC using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid_svc = {\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "svc_model = SVC()\n",
    "grid_search_svc = GridSearchCV(svc_model, param_grid_svc, scoring='accuracy', cv=5)\n",
    "grid_search_svc.fit(X_train, y_train)\n",
    "best_params_svc = grid_search_svc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the best SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svc_model_best = SVC(**best_params_svc)\n",
    "svc_model_best.fit(X_train, y_train)\n",
    "svc_predictions = svc_model_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning for RandomForestClassifier using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, scoring='accuracy', cv=5)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "best_params_rf = grid_search_rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the best RandomForestClassifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_model_best = RandomForestClassifier(**best_params_rf, random_state=42)\n",
    "rf_model_best.fit(X_train, y_train)\n",
    "rf_predictions = rf_model_best.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning for GradientBoostingClassifier using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "grid_search_gb = GridSearchCV(gb_model, param_grid_gb, scoring='accuracy', cv=5)\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "best_params_gb = grid_search_gb.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the best GradientBoostingClassifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gb_model_best = GradientBoostingClassifier(**best_params_gb, random_state=42)\n",
    "gb_model_best.fit(X_train, y_train)\n",
    "gb_predictions = gb_model_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Multinomial Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "nb_precision = precision_score(y_test, nb_predictions, pos_label='spam')\n",
    "nb_recall = recall_score(y_test, nb_predictions, pos_label='spam')\n",
    "nb_f1 = f1_score(y_test, nb_predictions, pos_label='spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svc_accuracy = accuracy_score(y_test, svc_predictions)\n",
    "svc_precision = precision_score(y_test, svc_predictions, pos_label='spam')\n",
    "svc_recall = recall_score(y_test, svc_predictions, pos_label='spam')\n",
    "svc_f1 = f1_score(y_test, svc_predictions, pos_label='spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate RandomForestClassifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "rf_precision = precision_score(y_test, rf_predictions, pos_label='spam')\n",
    "rf_recall = recall_score(y_test, rf_predictions, pos_label='spam')\n",
    "rf_f1 = f1_score(y_test, rf_predictions, pos_label='spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate GradientBoostingClassifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gb_accuracy = accuracy_score(y_test, gb_predictions)\n",
    "gb_precision = precision_score(y_test, gb_predictions, pos_label='spam')\n",
    "gb_recall = recall_score(y_test, gb_predictions, pos_label='spam')\n",
    "gb_f1 = f1_score(y_test, gb_predictions, pos_label='spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Accuracy: 0.9632286995515695\n",
      "Multinomial Naive Bayes Precision: 0.8222222222222222\n",
      "Multinomial Naive Bayes Recall: 0.9426751592356688\n",
      "Multinomial Naive Bayes F1 Score: 0.8783382789317508\n",
      "SVC Accuracy: 0.979372197309417\n",
      "SVC Precision: 0.9785714285714285\n",
      "SVC Recall: 0.8726114649681529\n",
      "SVC F1 Score: 0.9225589225589226\n",
      "Random Forest Accuracy: 0.97847533632287\n",
      "Random Forest Precision: 1.0\n",
      "Random Forest Recall: 0.8471337579617835\n",
      "Random Forest F1 Score: 0.9172413793103448\n",
      "Gradient Boosting Accuracy: 0.9748878923766816\n",
      "Gradient Boosting Precision: 0.9708029197080292\n",
      "Gradient Boosting Recall: 0.8471337579617835\n",
      "Gradient Boosting F1 Score: 0.9047619047619048\n"
     ]
    }
   ],
   "source": [
    "print(f'Multinomial Naive Bayes Accuracy: {nb_accuracy}')\n",
    "print(f'Multinomial Naive Bayes Precision: {nb_precision}')\n",
    "print(f'Multinomial Naive Bayes Recall: {nb_recall}')\n",
    "print(f'Multinomial Naive Bayes F1 Score: {nb_f1}')\n",
    "\n",
    "print(f'SVC Accuracy: {svc_accuracy}')\n",
    "print(f'SVC Precision: {svc_precision}')\n",
    "print(f'SVC Recall: {svc_recall}')\n",
    "print(f'SVC F1 Score: {svc_f1}')\n",
    "\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n",
    "print(f'Random Forest Precision: {rf_precision}')\n",
    "print(f'Random Forest Recall: {rf_recall}')\n",
    "print(f'Random Forest F1 Score: {rf_f1}')\n",
    "\n",
    "print(f'Gradient Boosting Accuracy: {gb_accuracy}')\n",
    "print(f'Gradient Boosting Precision: {gb_precision}')\n",
    "print(f'Gradient Boosting Recall: {gb_recall}')\n",
    "print(f'Gradient Boosting F1 Score: {gb_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose the best model based on accuracy and other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is: SVC\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_model = None\n",
    "best_model_name = \"\"\n",
    "best_model_accuracy = 0\n",
    "\n",
    "models = [\n",
    "    (\"Multinomial Naive Bayes\", nb_accuracy, nb_model),\n",
    "    (\"SVC\", svc_accuracy, svc_model_best),\n",
    "    (\"Random Forest\", rf_accuracy, rf_model_best),\n",
    "    (\"Gradient Boosting\", gb_accuracy, gb_model_best)\n",
    "]\n",
    "\n",
    "for name, accuracy, model in models:\n",
    "    if accuracy > best_model_accuracy:\n",
    "        best_model_accuracy = accuracy\n",
    "        best_model = model\n",
    "        best_model_name = name\n",
    "\n",
    "print(f'The best model is: {best_model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the best model and vectorizer using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "with open(f'{best_model_name.lower().replace(\" \", \"_\")}.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
